# ğŸ§  SL-MAI â€“ Ein kleines deutsches Sprachmodell (SLM) mit Python

SL-MAI ist ein kleines, vollstÃ¤ndig lokal ausfÃ¼hrbares German Small Language Model (SLM).  
Es wurde mit Python, PyTorch und einem eigenen BPE-Tokenizer trainiert.  

Das Projekt richtet sich an alle, die:

- ihr **eigenes KI-Modell** trainieren wollen  
- ein **vollstÃ¤ndig offline laufendes SLM** suchen  
- verstehen mÃ¶chten, wie Tokenizer, Training und Sampling zusammenarbeiten  
- eine erweiterbare Basis fÃ¼r Experimente oder Forschung brauchen  


---

# ğŸš€ FunktionsÃ¼bersicht

| Funktion | Beschreibung |
|---------|--------------|
| **Eigener BPE-Tokenizer** | Keine externen Modelle notwendig â€“ alles wird lokal trainiert. |
| **MiniGPT-Architektur** | Ein kleines GPT-Modell mit Embeddings, Self-Attention & Feedforward. |
| **Offline-Training** | Keine API, kein Internet, keine Cloud. |
| **Fortsetzbares Training** | Checkpoint-System (`checkpoint.pt`). |
| **2 GUI-Versionen** | V1 (Basic), V2 (Stil + Kontext + Reranking). |
| **Prompt-Stilspeicher (memory.json)** | Die KI passt Satzbau & Stil an deine Prompts an. |
| **Kontext-Modus (optional)** | Folgefragen erkennen (â€Wann erschien das Spiel?â€œ). |
| **Temperatur, Top-K & Kandidaten-Reranking** | Voll kontrollierbare Textgenerierung. |

---

# ğŸ“ Projektstruktur

```
sl-mai/
â”‚
â”œâ”€â”€ train.py                     # Training des Modells
â”œâ”€â”€ model.py                     # MiniGPT Architektur
â”œâ”€â”€ tokenizer.py                 # BPE-Tokenizer
â”œâ”€â”€ data.py                      # Dataset / Block-Handling
â”œâ”€â”€ gui_generate_V1.py           # Einfache GUI ohne Kontext
â”œâ”€â”€ gui_generate_V2.py           # Erweiterte GUI (Stil, Satzbau, Kontext)
â”œâ”€â”€ memory.py                    # Prompt-Speicher + Stilprofil
â”‚â”€â”€ latest_training_files/
    |
    |â”€â”€ grundwissen.txt              # Deine Trainingsdaten (muss man selbst hinzufÃ¼gen)
    |â”€â”€ tokenizer.json               # Nach Training erzeugt
    â”œâ”€â”€ checkpoint.pt                # Fortsetzbarer Trainingszustand
    â”œâ”€â”€ minigpt_grundwissen.pt       # Fertiges Modell
â”‚
â””â”€â”€ LICENSE                      # Lizenzbestimmungen
```

---

# ğŸ“˜ 1. Voraussetzungen

### ğŸ Python 3.9â€“3.12  
### ğŸ”§ Module installieren:

```
pip install torch
```

und evtl.

```
pip install tkinter
```

(Unter Windows ist `tkinter` normalerweise bereits vorhanden.)

---

# ğŸ“˜ 2. Trainingsdaten: `grundwissen.txt`

Du musst im Projektordner eine Datei `grundwissen.txt` erstellen.

### Empfohlen:

- **UTF-8 Text**
- **deutsche, vollstÃ¤ndige SÃ¤tze**
- **mind. 200 KB**, besser **800 KB â€“ 2 MB**
- **Themenmix:** Wissenschaft, ErklÃ¤rungen, Geschichte, Technologie, Q&A usw.
- Die KI lernt *nur* das, was hier drin steht  
  â†’ je besser der Text, desto besser das Modell.

âš ï¸ **Wichtig:**  
Deine Trainingsdaten dÃ¼rfen KEINE persÃ¶nlichen Daten enthalten.  
Nur neutrale, allgemein gÃ¼ltige Texte verwenden.

---

# ğŸ‹ï¸ 3. Training starten

In den Projektordner wechseln:

```
cd sl-mai
```

Training ausfÃ¼hren:

```
python train.py
```

Du wirst gefragt:

```
Gib die Anzahl der Epochen an, die erreicht werden sollen:
Gib die Batches pro Epoche an:
```

### Beispiel (empfohlen):

```
80
250
```

### WÃ¤hrend des Trainings werden erzeugt:

| Datei | Zweck |
|-------|-------|
| `tokenizer.json` | Dein Tokenizer |
| `checkpoint.pt` | Fortsetzbarer Trainingsstand |
| `minigpt_grundwissen.pt` | Das finale Modell |

Das Training kann jederzeit abgebrochen werden â€“  
beim nÃ¤chsten Start wird automatisch fortgesetzt.

---

# ğŸ’¬ 4. Nutzung der GUIs

---

## ğŸ›ï¸ **V1: Einfache GUI â€“ keine Stillogik, kein Kontext**

```
python gui_generate_V1.py
```

Eigenschaften:

- beantwortet jede Frage separat  
- keine StilÃ¼bernahme  
- keine Prompt-Analyse  
- stabil & minimal

---

## ğŸ›ï¸ **V2: Erweiterte GUI â€“ Stil, Satzstruktur, Kontext**

```
python gui_generate_V2.py
```

### Funktionen:

#### ğŸŸ¦ **Stil-Einfluss (Slider 0â€“1)**
Je hÃ¶her der Wert, desto stÃ¤rker orientiert sich die KI an:

- Satzbau deiner gespeicherten Prompts  
- Wortwahl  
- typischem Schreibstil  

#### ğŸŸ© **Interne Kandidaten (1â€“10)**  
Das Modell erzeugt mehrere RohvorschlÃ¤ge.  
Danach findet ein **Reranking** statt:

1. Grammatikpunkte  
2. Satzzeichen  
3. deutsche WÃ¶rter  
4. Wiederholungsstrafe  
5. StilÃ¤hnlichkeit  
6. Prompt-Ã„hnlichkeit  

â†’ Die **beste** Antwort wird angezeigt.

#### ğŸ”¥ **Temperatur (0.3â€“0.7)**  
- Niedrig â†’ prÃ¤zise, strikt, weniger kreativ  
- Hoch â†’ kreativer, aber chaotischer  

#### ğŸŸ§ **Kontextmodus (Checkbox)**  
Wenn aktiviert, erkennt die KI einfache Folgefragen:

**Beispiel:**

Prompt 1:
> Warum ist Minecraft beliebt?

Prompt 2:
> Wann ist das Spiel erschienen?

â†’ Die KI weiÃŸ: â€das Spielâ€œ = Minecraft.  
(Kommt auf TrainingsqualitÃ¤t + Prompt-Stil an.)

---

# ğŸ§  5. Wie die KI lernt (Wichtig!)

SL-MAI lernt **nicht** live aus Antworten.  
Er lernt aus zwei Dingen:

### 1. **Deinen Trainingsdaten (`grundwissen.txt`)**
â€“ beeinflussen Wissen  
â€“ beeinflussen SprachqualitÃ¤t  
â€“ beeinflussen Satzbau  
â€“ verÃ¤ndern Gewichte â†’ Training nÃ¶tig  

### 2. **Deinen Prompts (memory.json)**
â€“ beeinflussen Stil  
â€“ beeinflussen Wortwahl  
â€“ beeinflussen Satzstruktur  
â€“ *kein Training nÃ¶tig*  
â€“ KI passt sich dynamisch an (Version V2)

---

# âš ï¸ EinschrÃ¤nkungen & Hinweise

- SL-MAI ist ein **Mini-Modell**, kein GPT-4.  
- Es versteht Themen *oberflÃ¤chlich*, abhÃ¤ngig vom Training.  
- Es erfindet gelegentlich Fakten (â€Halluzinationenâ€œ).  
- Kontext funktioniert nur in einfacher Form.  
- Sehr prÃ¤zise Aufgaben Ã¼bersteigen ein Mini-SLM.

---

# ğŸ“œ 6. Lizenz (wichtiger Abschnitt)

Dieses Projekt ist **nicht-kommerziell**.  
Die Nutzung des Codes ist erlaubt, aber:

- Modelle dÃ¼rfen **nicht kommerziell genutzt werden**  
- Trainingsdaten dÃ¼rfen **nicht wiederverwendet oder weiterverkauft werden**  
- Der Name â€Yenoyoshâ€œ muss genannt werden  
- Die KI selbst darf **nicht als Dienst angeboten werden**

Siehe vollstÃ¤ndige `LICENSE` im Repository.

---

# ğŸ’¡ 7. Beispiel-Prompt

```
Warum ist Photosynthese wichtig?
```

Beispielantwort (abhÃ¤ngig vom Training):

> Die Photosynthese ist wichtig, weil sie Pflanzen ermÃ¶glicht, Lichtenergie in chemische Energie umzuwandeln und gleichzeitig Sauerstoff produziert, der fÃ¼r viele Lebewesen lebensnotwendig ist.

---

# ğŸ§© 8. Erweiterungen (optional)

Du kannst SL-MAI leicht erweitern:

- grÃ¶ÃŸere Modelle (mehr Layer, mehr Heads)  
- grÃ¶ÃŸere Trainingsdaten  
- Kontextfenster erhÃ¶hen (block_size z. B. 128)  
- grammatikbasierte Filter  
- POS-Tagger fÃ¼r echte Satzstrukturkontrolle  
- Reinforcement Learning fÃ¼r Stiloptimierung  

---

# ğŸ’– 9. Autor

**Yenoyosh**  
2025

---

# âœ”ï¸ Projektstatus

SL-MAI ist funktional, trainierbar und erweiterbar.  
Das Modell verbessert sich mit jeder Epoche und jeder Erweiterung.

BeitrÃ¤ge und Forks sind willkommen.
